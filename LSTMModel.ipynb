import os
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb=16384'

import numpy as np
import pandas as pd
import torch
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset, DataLoader
import pywt 
from sklearn.preprocessing import LabelBinarizer
from sklearn.preprocessing import OneHotEncoder
import torch.nn.functional as F

np.random.seed(123)
batch_size = 32

class EcgDataset(Dataset):
    def __init__(self, data, labels):
        self.data = data
        self.labels = labels
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        return self.data[idx], self.labels[idx]

# def extract_wavelet_features(data, wavelet='db4', level=4):
#     # Apply wavelet transform to the ECG data
#     data = data.squeeze().cpu().numpy()
#     coeffs = pywt.wavedec(data, wavelet, level=level)

#     # Concatenate the wavelet coefficients into a feature vector
#     features = np.concatenate(coeffs)
#     #print("features shape:",features.shape)
#     return features

def get_train_val_test_masks(data_len, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2, batch_size=batch_size):
    assert train_ratio + val_ratio + test_ratio == 1.0, "Train/val/test ratios must sum to 1.0"

    indices = np.arange(data_len)
    np.random.shuffle(indices)
    train_end_idx = int(data_len * train_ratio)
    train_end_idx -= train_end_idx % batch_size
    val_end_idx = int(data_len * (train_ratio + val_ratio))
    val_end_idx -= val_end_idx % batch_size
    test_end_idx = data_len

    train_mask = torch.from_numpy(indices[:train_end_idx])
    val_mask = torch.from_numpy(indices[train_end_idx:val_end_idx])
    test_mask = torch.from_numpy(indices[val_end_idx:test_end_idx])


    return train_mask, val_mask, test_mask

def ecg_dataset(data_dir, csv_file):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # Load the CSV file into a Pandas dataframe
    df = pd.read_csv(csv_file)

    # Find all .npy files in the directory tree
    all_files = [os.path.join(dirpath, filename) for dirpath, _, filenames in os.walk(data_dir) for filename in filenames if filename.endswith('.npy')]

    # Filter the list of file paths to only include those in the set of file names
    selected_files = [file_path for file_path in all_files if os.path.basename(file_path) in set(df['npyfile'])]

    # Load the data from the selected .npy files into a list of NumPy arrays
    all_data = torch.empty((len(selected_files), 65000), dtype=torch.float, device=device)
    for i, file_path in enumerate(selected_files):
        arr = np.load(file_path)[:65000]
        if arr.shape == (65000,):
            all_data[i] = torch.from_numpy(arr)
        else:
            print(f"Array {os.path.basename(file_path)} has incorrect shape {arr.shape}. Skipping.")
    print("Number of loaded arrays:", len(all_data))

    # Create an array of labels from the ground truth CSV file
    df = df[df['npyfile'].isin([os.path.basename(file_path) for file_path in selected_files])]
    y = df['Stress'].values
    y = np.where(y >= 4, 1, 0)

    print("Stress range:", df['Stress'].min(), "-", df['Stress'].max())
       
    # Transform the labels using one-hot encoding
    y = torch.from_numpy(y)
    y = torch.nn.functional.one_hot(y, num_classes=2)
    
    print("y,",y)

#     # Extract wavelet features from the data
#     X_features = []
#     for data in all_data:
#         X_features.append(extract_wavelet_features(data))
#     X_features = np.array(X_features)
#     print("X_features shape:",X_features.shape)
    # Select 10 random indices
    indices = np.random.choice(len(all_data), size=10, replace=False)
#     np.set_printoptions(threshold=np.inf)
    # Print the corresponding features
    for idx in indices:
        print(f'Features for sample {idx}: {all_data[idx]}')

    # Shuffle the data and labels arrays in the same way
    indices = np.arange(len(all_data))
    np.random.shuffle(indices)
    X_features = all_data[indices]
    y = y[indices]
    # print("Y:",y[indices])
    np.set_printoptions(threshold=np.inf)

     # Split the data into training and test sets
    train_mask, val_mask, test_mask = get_train_val_test_masks(len(all_data))
    X_train = all_data[train_mask].unsqueeze(-1).detach().cpu().numpy()
    y_train = y[train_mask].to(device)
    np.set_printoptions(threshold=np.inf)
    print("y_train:",y_train)
    y_train_np = y_train.cpu().numpy()
    np.set_printoptions(threshold=np.inf)
    print("y_train:", y_train_np)
    print("y_train length:",len(y_train))
    print("x_train:",len(X_train))
    X_val = all_data[val_mask].unsqueeze(-1).detach().cpu().numpy()
    y_val = y[val_mask].to(device)
    print("y_val:",y_val)
    print("y_val length:",len(y_val))
    print("X_val length:",len(X_val))
    X_test = all_data[test_mask].unsqueeze(-1).detach().cpu().numpy()
    y_test = y[test_mask].to(device)
    print("y_test:",y_test)
    print("y_test length:",len(y_test))
    print("X_test length:",len(X_test))
    X_train = X_train.reshape(-1, 65000, 1)
    X_val = X_val.reshape(-1, 65000, 1)
    X_test = X_test.reshape(-1, 65000, 1)

    # Create datasets
    train_dataset = EcgDataset(X_train, y_train)
    val_dataset = EcgDataset(X_val, y_val)
    test_dataset = EcgDataset(X_test, y_test)

    print("Training dataset:")
    print(f"Number of samples: {len(train_dataset)}")
    print(f"Data shape: {train_dataset.data.shape}")
    print(f"Labels shape: {train_dataset.labels.shape}")
    print("Training dataset labels:")
    print(train_dataset.labels)

    return train_dataset, val_dataset, test_dataset
    


# Example usage
data_dir = '/kaggle/input/ecgdata'
csv_file = '/kaggle/input/groundtruth/Ground_truth_stress_level.csv'
train_dataset, val_dataset, test_dataset = ecg_dataset(data_dir, csv_file)


train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
import torch.nn as nn
import torch.nn.functional as F
from sklearn.preprocessing import LabelBinarizer

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

class LSTMModel(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(LSTMModel, self).__init__()
        self.hidden_dim = hidden_dim
        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)
        self.fc1 = nn.Linear(hidden_dim, 64)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(64, output_dim)
        self.sigmoid = nn.Sigmoid()

        # Define the weights for the loss function
#         self.class_weights = torch.tensor([1/0.33, 1/0.22, 1/0.13, 1/0.1, 1/0.086, 1/0.05, 1/0.01, 1/0.01, 1/0.01, 1/0.01]).to(device)
        self.class_weights = torch.tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1]).to(device)

        self.criterion = nn.BCEWithLogitsLoss(weight=self.class_weights)

    def forward(self, x):
        h0 = torch.zeros(1, x.size(0), self.hidden_dim).to(x.device)
        c0 = torch.zeros(1, x.size(0), self.hidden_dim).to(x.device)
        out, (h_n, c_n) = self.lstm(x, (h0, c0))
        out = self.fc1(out[:, -1, :])
        out = self.relu(out)
        out = self.fc2(out)
        out = self.sigmoid(out)

        return out

    def loss_fn(self, y_pred, y_true):
        # Calculate the weighted loss using binary cross-entropy with logits and the class weights
        loss = self.criterion(y_pred, y_true)
        return loss
    
# Define hyperparameters
input_dim = 1
hidden_dim = 128
output_dim = 10
learning_rate = 0.0001
num_epochs = 10

model = LSTMModel(input_dim, hidden_dim, output_dim).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
output_file = "output.txt"
criterion = nn.BCEWithLogitsLoss(weight=model.class_weights)

def train(model, loader, optimizer, criterion):
    for epoch in range(num_epochs):

        model.train()
        train_loss = 0
        train_acc = 0
        with open(output_file, "w") as f:

            for i, (data, labels) in enumerate(loader):
                data = data.float().to(device) # Convert input tensor to float before passing to LSTM
                labels = labels.to(device).float()
                #print(labels)  # print the labels

                optimizer.zero_grad()
                outputs = model(data)
                labels = labels.to(device)

                # use weighted cross entropy loss
                loss = criterion(outputs, labels)
                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)


                optimizer.step()

                train_loss += loss.item()
                predicted = outputs.argmax(dim=1)
                one_hot_predicted = F.one_hot(predicted, num_classes=outputs.shape[-1])
                train_acc += (one_hot_predicted == labels).all(dim=1).sum().item()
                f.write(f"Training labels: {labels}\n")
                f.write(f"Training outputs floats: {outputs}\n")
                # print the loss and accuracy every 10 batches
                if (i+1) % 10 == 0:
                    avg_loss = train_loss / (i+1)
                    total_examples = (i+1) * labels.size(0)
avg_acc = train_acc / total_examples
                    avg_acc = train_acc / ((i+1) * labels.size(0))
                    print(f"Batch {i+1}, Loss: {avg_loss:.4f}, Accuracy: {avg_acc:.4f}")
            train_loss /= len(loader.dataset)
            train_acc /= len(loader.dataset)
        print(f"Epoch {epoch+1}, Training Loss: {train_loss:.4f}, Training Accuracy: {train_acc:.4f}")

    return train_loss, train_acc

train_loss, train_acc = train(model, train_loader, optimizer, criterion)

def evaluate(model, loader, criterion):
    
    model.eval()
    val_loss = 0
    val_acc = 0
    val_correct = 0
    with torch.no_grad():
        for i, (data, labels) in enumerate(loader):
            #print(labels)  # print the labels
            data = data.float().to(device) # Convert input tensor to float before passing to LSTM
            labels = labels.to(device).float()
            
            outputs = model(data)
            labels = labels.cpu().numpy()  # Convert tensor to numpy array
            labels = torch.from_numpy(labels).to(device).float()
            
            # Compute weighted loss
            loss = criterion(outputs, labels)


            predicted = outputs.argmax(dim=1)
            one_hot_predicted = F.one_hot(predicted, num_classes=outputs.shape[-1])
            val_acc += (one_hot_predicted == labels).sum().item()
            val_loss += loss.item()
            val_correct += (one_hot_predicted == labels.unsqueeze(1).long()).sum().item()
#             print("outputs:",outputs)
#             print(f"One Hot Predicted: {one_hot_predicted}")
#             print(f"validation Labels: {labels}")

            # Print the loss and accuracy every 10 batches
            if i % 10 == 0:
                print(f"Validation Batch {i}/{len(loader)}, Loss: {loss.item():.4f}, Accuracy: {(one_hot_predicted == labels).sum().item()/len(labels):.4f}")

        val_loss /= len(loader.dataset)
        val_acc /= len(loader.dataset)
    print(f"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}")
    return val_loss, val_acc

val_loss, val_acc = evaluate(model, val_loader, criterion)


# Evaluate the model on the test set
model.eval()
test_loss = 0
test_acc = 0
with torch.no_grad():
    for data, labels in test_loader:
        data = data.to(device)
        labels = labels.to(device).float()
        outputs = model(data)
        loss = criterion(outputs, labels)
        predicted = outputs.argmax(dim=1)
        one_hot_predicted = F.one_hot(predicted, num_classes=outputs.shape[-1])
        test_loss += loss.item()
        test_acc += (one_hot_predicted == labels).sum().item()

    test_loss /= len(test_loader.dataset)
    test_acc /= len(test_loader.dataset)

print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}")
